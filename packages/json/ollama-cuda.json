{"pkgname": "ollama-cuda", "pkgbase": "ollama-cuda", "repo": "extra", "arch": "x86_64", "pkgver": "0.3.12", "pkgrel": "5", "epoch": 0, "pkgdesc": "Create, run and share large language models (LLMs) with CUDA", "url": "https://github.com/ollama/ollama", "filename": "ollama-cuda-0.3.12-5-x86_64.pkg.tar.zst", "compressed_size": 266672216, "installed_size": 292184959, "build_date": "2024-11-09T17:48:34Z", "last_update": "2024-11-09T19:05:51.350Z", "flag_date": "2024-10-12T20:54:08.004Z", "maintainers": ["arodseth", "svenstaro"], "packager": "arodseth", "groups": [], "licenses": ["MIT"], "conflicts": ["ollama"], "provides": ["ollama"], "replaces": [], "depends": [], "optdepends": ["nvidia-utils: monitor GPU usage with nvidia-smi"], "makedepends": ["clblast", "cmake", "cuda", "git", "go"], "checkdepends": []}